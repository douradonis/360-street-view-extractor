import os
import math
import cv2
import numpy as np
from PIL import Image
import piexif
from xml.dom import minidom
from streetview import search_panoramas, get_panorama
from ultralytics import YOLO

# =========================
# CONFIG
# =========================
INPUT_KML = "route.kml"
OUT_IMG = "output/images"
OUT_MASK = "output/masks"
os.makedirs(OUT_IMG, exist_ok=True)
os.makedirs(OUT_MASK, exist_ok=True)

OUT_SIZE = 4096          # High-res output
FOV = 90                  # Perspective FOV
YAW_OFFSETS = [-70, -50, -30, -10, 10, 30, 50, 70]
PITCH_ROAD = -10          # Slightly downward to focus on road
MASK_CLASSES = {"person", "car", "motorcycle", "bus", "truck"}
DEFAULT_ALT = 2.5

# =========================
# UTILS
# =========================
def deg_to_dms_rational(deg):
    d = int(deg)
    m = int((deg - d) * 60)
    s = (deg - d - m / 60) * 3600
    return [(d,1),(m,1),(int(s*100),100)]

def write_gps(path, lat, lon, alt=DEFAULT_ALT):
    img = Image.open(path)
    exif_bytes = img.info.get("exif")
    if exif_bytes:
        exif_dict = piexif.load(exif_bytes)
    else:
        exif_dict = {"0th":{}, "Exif":{}, "GPS":{}, "Interop":{}, "1st":{}, "thumbnail":None}
    exif_dict["GPS"] = {
        piexif.GPSIFD.GPSLatitudeRef: "N" if lat >=0 else "S",
        piexif.GPSIFD.GPSLatitude: deg_to_dms_rational(abs(lat)),
        piexif.GPSIFD.GPSLongitudeRef: "E" if lon >=0 else "W",
        piexif.GPSIFD.GPSLongitude: deg_to_dms_rational(abs(lon)),
        piexif.GPSIFD.GPSAltitude: (int(alt*100),100),
    }
    piexif.insert(piexif.dump(exif_dict), path)

def bearing(lat1, lon1, lat2, lon2):
    Ï†1, Ï†2 = math.radians(lat1), math.radians(lat2)
    Î”Î» = math.radians(lon2 - lon1)
    x = math.sin(Î”Î») * math.cos(Ï†2)
    y = math.cos(Ï†1)*math.sin(Ï†2) - math.sin(Ï†1)*math.cos(Ï†2)*math.cos(Î”Î»)
    Î¸ = math.atan2(x, y)
    return math.degrees(Î¸) % 360

def extract_view_spherical(img, yaw_deg, pitch_deg=-10, fov_deg=90, out_size=4096):
    """
    Correct perspective from equirectangular panorama using spherical projection.
    Avoids bottom wrap distortion.
    """
    h, w = img.shape[:2]
    fov = np.deg2rad(fov_deg)
    yaw = np.deg2rad(yaw_deg)
    pitch = np.deg2rad(pitch_deg)

    # Focal length for perspective
    f = (out_size/2) / np.tan(fov/2)

    # Pixel grid
    xs = np.linspace(-out_size/2, out_size/2-1, out_size)
    ys = np.linspace(-out_size/2, out_size/2-1, out_size)
    xx, yy = np.meshgrid(xs, ys)

    # Camera coordinates
    z = f * np.ones_like(xx)
    x_cam = xx
    y_cam = -yy  # Flip Y for correct orientation
    vec = np.stack([x_cam, y_cam, z], axis=-1)
    vec /= np.linalg.norm(vec, axis=-1, keepdims=True)

    # Rotation matrix
    Rx = np.array([
        [1,0,0],
        [0,np.cos(pitch),-np.sin(pitch)],
        [0,np.sin(pitch), np.cos(pitch)]
    ])
    Ry = np.array([
        [np.cos(yaw),0,np.sin(yaw)],
        [0,1,0],
        [-np.sin(yaw),0,np.cos(yaw)]
    ])
    R = Ry @ Rx

    # Rotate vectors
    vec_rot = vec @ R.T

    # Spherical coordinates
    theta = np.arctan2(vec_rot[...,0], vec_rot[...,2])
    phi = np.arcsin(vec_rot[...,1])

    # Normalize phi to avoid bottom wrap distortion
    # Limit phi to avoid poles (0.25 rad buffer)
    phi = np.clip(phi, -np.pi/2 + 0.05, np.pi/2 - 0.05)

    # Map to equirectangular
    u = (theta/np.pi + 1) * w/2
    v = (0.5 - phi/np.pi) * h

    persp = cv2.remap(img, u.astype(np.float32), v.astype(np.float32),
                       interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_WRAP)
    return persp

def interpolate_path(coords, step_meters=5):
    points = []
    for i in range(len(coords)-1):
        lat1, lon1 = coords[i]
        lat2, lon2 = coords[i+1]

        # Haversine distance
        R = 6371000
        dlat = math.radians(lat2-lat1)
        dlon = math.radians(lon2-lon1)
        a = math.sin(dlat/2)**2 + math.cos(math.radians(lat1))*math.cos(math.radians(lat2))*math.sin(dlon/2)**2
        c = 2*math.atan2(math.sqrt(a), math.sqrt(1-a))
        dist = R * c

        steps = max(1, int(dist/step_meters))
        for s in range(steps):
            f = s/steps
            lat = lat1 + f*(lat2-lat1)
            lon = lon1 + f*(lon2-lon1)
            points.append((lat, lon))
    points.append(coords[-1])
    return points
    
def parse_kml_points(kml_file):
    doc = minidom.parse(kml_file)
    coords = []
    for linestring in doc.getElementsByTagName("LineString"):
        for coord_tag in linestring.getElementsByTagName("coordinates"):
            raw = coord_tag.firstChild.nodeValue.strip()
            for line in raw.split():
                lon, lat, *_ = map(float, line.split(","))
                coords.append((lat, lon))
    return coords

# =========================
# INIT YOLO
# =========================
model = YOLO("yolov8n-seg.pt")

# =========================
# MAIN PIPELINE
# =========================
coords = parse_kml_points(INPUT_KML)

for i, (lat, lon) in enumerate(coords):
    print(f"ðŸ“ Point {i+1}/{len(coords)}: {lat},{lon}")

    # ---------- SEARCH LATEST PANORAMA ----------
    try:
        panos = search_panoramas(lat, lon)
        if not panos:
            print("âš ï¸ No panorama found, skipping")
            continue
        pano = panos[0]
    except Exception as e:
        print("âš ï¸ Street View search failed:", e)
        continue

    # ---------- DOWNLOAD PANORAMA ----------
    try:
        img = get_panorama(pano.pano_id)
        pano_img = np.array(img)
        h, w = pano_img.shape[:2]
    except Exception as e:
        print("âš ï¸ Failed to download pano:", e)
        continue

    # ---------- FULL PANO MASK ----------
    full_mask = np.zeros((h, w), dtype=np.uint8)
    results = model(pano_img, imgsz=1024, conf=0.3)
    for r in results:
        if r.masks is None:
            continue
        for cls, seg in zip(r.boxes.cls, r.masks.data):
            label = model.names[int(cls)]
            if label in MASK_CLASSES:
                seg = seg.cpu().numpy().astype(np.uint8)*255
                seg = cv2.resize(seg,(w,h))
                full_mask = cv2.bitwise_or(full_mask, seg)
    full_mask[:int(h*0.25), :] = 255  # Sky mask
    pano_img[full_mask>0] = 0

    # ---------- CALCULATE FORWARD YAW ----------
    if i < len(coords)-1:
        next_lat, next_lon = coords[i+1]
        center_yaw = bearing(lat, lon, next_lat, next_lon)
    else:
        center_yaw = 0

    base = f"pano_{i:03d}"

    # ---------- SPLIT 8 FORWARD-CAMERAS ----------
    for j, offset in enumerate(YAW_OFFSETS):
        yaw = (center_yaw + offset) % 360
        view = extract_view_spherical(pano_img, yaw_deg=yaw, pitch_deg=-10, fov_deg=90, out_size=4096)
        mask_view = extract_view_spherical(full_mask, yaw_deg=yaw, pitch_deg=-10, fov_deg=90, out_size=4096)

        img_name = f"{base}_cam{j}.jpg"
        mask_name = f"{base}_cam{j}_mask.png"

        img_path = os.path.join(OUT_IMG, img_name)
        mask_path = os.path.join(OUT_MASK, mask_name)

        cv2.imwrite(img_path, view)
        cv2.imwrite(mask_path, mask_view)

        write_gps(img_path, lat, lon)

print("\nâœ… PIPELINE COMPLETE â€” 8 forward-biased high-res cameras ready for RealityScan")
